#! /usr/bin/env python
# coding: utf-8
'''
Nyanco/src/feature_extractor.py
Created on 18 Oct. 2012
'''
__author__ = "Yu Sawai"
__copyright__ = "Copyright 2012, Yu Sawai"
__version__ = "0"
__status__ = "Prototyping"

from datetime import datetime
import logging
logfilename = datetime.now().strftime("detector_log_%Y%m%d_%H%M.log")
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', 
                    level=logging.DEBUG, filename='../log/'+logfilename)
import os
import sys
from pprint import pformat
from collections import defaultdict
import cPickle as pickle
from numpy import array
from pattern.text import en
import traceback
from nltk import ngrams as ng
try:
    from lsa_test.irstlm import *
except:
    from tool.irstlm_moc import *


class BCluster(object):
    bcdic = pickle.load(open("../sandbox/bc_256.pkl2", "rb"))

    @classmethod
    def getbits(cls, w):
        try:
            _bits = cls.bcdic[w]
        except KeyError:
            try:
                _bits = cls.bcdic[w.lower()]
            except KeyError:
                _bits = None
        except:
            raise
        return _bits

# just add prefix to given feature name
sourceF = lambda x: "S:"+x
targetF = lambda x: "T:"+x
commonF = lambda x: "C:"+x

def easyadapt(fdic, domain=None):
    # augF = {commonF(fn):1 for fn in fdic}
    augF = fdic
    sF = {sourceF(fn):1 for fn in fdic} if domain == "src" else {}
    tF = {targetF(fn):1 for fn in fdic} if domain == "tgt" else {}
    augF.update(sF)
    augF.update(tF)
    return augF


class SentenceFeatures(object):
    """
    Extractor for a sentence given as a list of lines
    (This is for parsed data generated by SENNA parser)
    """
    nullfeature = {"NULL":1}

    def __init__(self, tags=[], verb="", v_idx=None):
        self.v = verb
        self.features = defaultdict(float)
        self.col_suf = 0
        self.col_offset = None
        self.col_pos = 1
        self.col_chk = 2
        self.col_ner = 3
        self.col_pre = 4
        self.col_psg = -1
        try:
            # for extracting features from parsed data
            # (tab separated dataset in CoNLL like format given by SENNA parser)
            self.tags = [[s.strip() for s in t.split("\t")] for t in tags if not t is ""]
        except AttributeError, IndexError:
            # for extracting features from tags' list
            self.tags = [t for t in tags]
        except:
            print pformat(tags)
            raise
        if self.is_withoffset(self.tags[0]):
            self.col_offset = 1
            self.col_pos += 1
            self.col_chk += 1
            self.col_ner += 1
            self.col_pre += 1
            self.OFFSET = [tuple(t[self.col_offset].split()) for t in self.tags]
        else:
            self.OFFSET = None
        try:
            self.SUF = [t[self.col_suf] for t in self.tags]
            self.POS = [t[self.col_pos] for t in self.tags]
            self.v_idx = self._find_verb_idx() if not v_idx else v_idx
            self.CHK = self.get_BIEStag(self.col_chk, self.tags)
            self.NER = self.get_BIEStag(self.col_ner, self.tags)
            self.SRL = self.get_SRL()
        except Exception, e:
            logging.debug(pformat(tags))
            raise


    def _find_verb_idx(self):
        verbpos = [idx for idx, sufpos in enumerate(zip(self.SUF, self.POS)) 
                    if sufpos[0] == self.v and "VB" in sufpos[1]]
        if verbpos:
            return verbpos[0]
        else:
            SUF_l = [en.lemma(w) for w in self.SUF]
            verbpos = [idx for idx, sufpos in enumerate(zip(SUF_l, self.POS)) 
                        if sufpos[0] == self.v and "VB" in sufpos[1]]
            if verbpos:
                return verbpos[0]
            else:
                return None


    def getfeatures(self):
        self.bow()
        self.length()
        return self.features


    def gen_fn(self, l=None):
        return "_".join(l)


    def is_withoffset(self, tag=None):
        return True if tag[1].split()[0].isdigit() else False


    def get_SRL(self):
        _t = [t[self.col_pre] for t in self.tags if not t[self.col_pre] == "-"]
        srl = []
        for i, w in enumerate(_t):
            srl.append(self.get_BIEStag(self.col_pre+i+1, self.tags))
        print srl
        return srl


    def get_BIEStag(self, col=None, tag=None):
        _col = [t[col] for t in self.tags]
        try:
            idx_B = [(i, t.split("-")[-1]) for i, t in enumerate(_col) if t.startswith("B")]
            idx_E = [(i, t.split("-")[-1]) for i, t in enumerate(_col) if t.startswith("E")]
            idx_S = [(i, t.split("-")[-1]) for i, t in enumerate(_col) if t.startswith("S")]
            _be = [(t[0][1], t[0][0], t[1][0]) for t in zip(idx_B, idx_E)] if idx_B and idx_E else []
            _s = [(t[1], t[0], t[0]+1) for t in idx_S]
            return sorted(_be + _s, key=lambda x:x[1])
        except:
            return None


    def ngrams(self, n=5, v_idx=None):
        """
        Make a query for ngram frequency counter
        @takes:
            n :: N gram size (if n=5, [-2 -1 +1 +2])
            v_idx:: int, positional index of the checkpoint
        @returns:
            suf_ngram: {"suf_-2_the": 1, "suf_-1_cat": 1, ...}
            pos_ngram: {"suf_-2_DT": 1, "suf_-1_NN": 1, ...}
        """
        try:
            suf_ngram = {}
            pos_ngram = {}
            window = int((n - 1)/2)
            if not v_idx:
                v_idx = self.v_idx
            # core = self.WL[v_idx]
            _lefts = [word for index, word in enumerate(self.SUF) if index < v_idx and index != v_idx][-window:]
            _leftp = [word for index, word in enumerate(self.POS) if index < v_idx and index != v_idx][-window:]
            _rights = [word for index, word in enumerate(self.SUF) if index > v_idx and index != v_idx][:window]
            _rightp = [word for index, word in enumerate(self.POS) if index > v_idx and index != v_idx][:window]
            concats = _lefts + ["*V*"] + _rights
            concatp = _leftp + ["*V*"] + _rightp
            suf_unigram = {SimpleFeatureExtractor.gen_fn(["SUF1G", str(i-window), "".join(w)]):1 
                        for i, w in enumerate(concats) if w != "*V*"}
            pos_unigram = {SimpleFeatureExtractor.gen_fn(["POS1G", str(i-window), "".join(w)]):1 
                        for i, w in enumerate(concatp) if w != "*V*"}
            suf_bigram = {SimpleFeatureExtractor.gen_fn(["SUF2G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concats, 3)) if w[0] == "*V*" or w[2] == "*V*"} if n >= 5 else {}
            pos_bigram = {SimpleFeatureExtractor.gen_fn(["POS2G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concatp, 3)) if w[0] == "*V*" or w[2] == "*V*"} if n >= 5 else {}
            suf_trigram = {SimpleFeatureExtractor.gen_fn(["SUF3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concats, 4)) if w[0] == "*V*" or w[3] == "*V*"} if n >= 7 else {}
            pos_trigram = {SimpleFeatureExtractor.gen_fn(["POS3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concatp, 4)) if w[0] == "*V*" or w[3] == "*V*"} if n >= 7 else {}
            suf_c3gram = {SimpleFeatureExtractor.gen_fn(["SUF3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concats, 3)) if w[1] == "*V*"} if n >= 3 else {}
            # suf_c5gram = {SimpleFeatureExtractor.gen_fn(["SUF5G", "", "-".join(w)]):1 
            #             for i, w in enumerate(ng(concats, 5)) if w[2] == "*V*"} if n >= 5 else {}
            # suf_c7gram = {SimpleFeatureExtractor.gen_fn(["SUF7G", "", "-".join(w)]):1 
                        # for i, w in enumerate(ng(concats, 7)) if w[3] == "*V*"} if n >= 7 else {}
            pos_c3gram = {SimpleFeatureExtractor.gen_fn(["POS3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concatp, 3)) if w[1] == "*V*"} if n >= 3 else {}
            # pos_c5gram = {SimpleFeatureExtractor.gen_fn(["POS5G", "", "-".join(w)]):1 
            #             for i, w in enumerate(ng(concatp, 5)) if w[2] == "*V*"} if n >= 5 else {}
            # pos_c7gram = {SimpleFeatureExtractor.gen_fn(["POS7G", "", "-".join(w)]):1 
                        # for i, w in enumerate(ng(concatp, 7)) if w[3] == "*V*"} if n >= 7 else {}
            self.features.update(suf_unigram)
            self.features.update(pos_unigram)
            self.features.update(suf_bigram)
            self.features.update(pos_bigram)
            self.features.update(suf_trigram)
            self.features.update(pos_trigram)
            self.features.update(suf_c3gram)
            # self.features.update(suf_c5gram)
            # self.features.update(suf_c7gram)
            self.features.update(pos_c3gram)
            # self.features.update(pos_c5gram)
            # self.features.update(pos_c7gram)
        except Exception, e:
            raise
            # self.features.update(SimpleFeatureExtractor.nullfeature)

    def chunk(self, v_idx=None):
        try:
            if not v_idx:
                v_idx = self.v_idx
            l_ctxid = [idx for idx, pt in enumerate(self.POS) if idx < v_idx and pt.startswith("NN")]
            r_ctxid = [idx for idx, pt in enumerate(self.POS) if idx > v_idx and pt.startswith("NN")]
            lnn = self.SUF[l_ctxid[-1]] if l_ctxid else None
            rnn = self.SUF[r_ctxid[0]] if r_ctxid else None
            l_nearestNN = {"NNL_%s"%lnn: 1} if lnn else {}
            r_nearestNN = {"NNR_%s"%rnn : 1} if rnn else {}
            self.features.update(l_nearestNN)
            self.features.update(r_nearestNN)
            lnnbc = BCluster.getbits(lnn)
            rnnbc = BCluster.getbits(rnn)
            l_nearestNN = {"NNLBC%d_%s"%(d,lnnbc[:d]):1 for d in [7, 8, 9]} if lnnbc else {}
            r_nearestNN = {"NNRBC%d_%s"%(d,rnnbc[:d]):1 for d in [7, 8, 9]} if rnnbc else {}
            self.features.update(l_nearestNN)
            self.features.update(r_nearestNN)
        except:
            pass



class FeatureExtractorBase(object):
    """
    This is a base class of feature extractor for each parsed sentence
    (Assuming all parsed data are in CoNLLX format generated by FANSEPARSER)
    """
    nullfeature = {"NULL":1}
    VE_count = 0

    @classmethod
    def gen_fn(cls, l=None):
        return "_".join(l)

    @classmethod
    def set_col_f(cls):
        cls.conll_type = "full"
        cls.col_suf = 1
        cls.col_pos = 4
        cls.col_headid = 6
        cls.col_deprel = 7
        cls.col_netag = 10
        cls.col_srlrel = 12 
        cls.col_srl = 13

    @classmethod
    def set_col_r(cls):
        cls.conll_type = "reduced"
        cls.col_suf = 1
        cls.col_pos = 2
        cls.col_headid = 4
        cls.col_deprel = 3
        cls.col_netag = 5
        cls.col_srlrel = 6
        cls.col_srl = 7

    def __init__(self, tags=[], verb="", v_idx=None):
        self.features = defaultdict(float)
        self.v = verb
        try:
            # for extracting features from parsed data (tab separated dataset in CoNLL like format)
            self.tags = [t.split("\t") for t in tags if not t is ""]
            _t = len(self.tags[0])
            # print "FeatureExtractor: Num of column of tags is %d"%_t
            if _t == 14:
                FeatureExtractorBase.set_col_f()
            elif _t == 8:
                FeatureExtractorBase.set_col_r()
        except AttributeError, IndexError:
            # for extracting features from tags' list
            self.tags = tags
            _t = len(self.tags[0])
            # print "FeatureExtractor: Num of column of tags is %d"%_t
            if _t == 14:
                FeatureExtractorBase.set_col_f()
            elif _t == 8:
                FeatureExtractorBase.set_col_r()
        except:
            print verb
            print pformat(tags)
            raise
        try:
            self.SUF = [t[FeatureExtractorBase.col_suf].lower() for t in self.tags]
            self.POS = [t[FeatureExtractorBase.col_pos] for t in self.tags]
            self.WL = zip(self.SUF, self.POS)
            self.v_idx = self._find_verb_idx() if not v_idx else v_idx
            if self.v_idx is None:
                FeatureExtractorBase.VE_count += 1
                raise ValueError
            else:
                pass
                # print "verb is ", tags[self.v_idx]
        except Exception, e:
            # print pformat(["FeatureExtractor: ", e])
            # traceback.print_exc(file=sys.stdout)
            # print tags[0]
            # print pformat(tags)
            # logging.debug(pformat(tags))
            self.features.update(FeatureExtractorBase.nullfeature)


    def _find_verb_idx(self):
        verbpos = [idx for idx, sufpos in enumerate(zip(self.SUF, self.POS)) if sufpos[0] == self.v and "VB" in sufpos[1]]
        if verbpos:
            return verbpos[0]
        else:
            SUF_l = [en.lemma(w) for w in self.SUF]
            verbpos = [idx for idx, sufpos in enumerate(zip(SUF_l, self.POS)) if sufpos[0] == self.v and "VB" in sufpos[1]]
            if verbpos:
                return verbpos[0]
            else:
                return None

    @classmethod
    def read_corpusfiles(self, corpuspath=""):
        """
        This classmethod reads corpus (pickled files, separated by each verbs)
        from the given directory, 
        returns a dictionary for next process
        """
        corpusdict = defaultdict(list)
        raise NotImplementedError


    def save_to_file(self):
        raise NotImplementedError


class SimpleFeatureExtractor(FeatureExtractorBase):
    """
    Extract features for given case, 

    """

    def ngrams(self, n=5, v_idx=None):
        """
        Make a query for ngram frequency counter
        @takes:
            n :: N gram size (if n=5, [-2 -1 +1 +2])
            v_idx:: int, positional index of the checkpoint
        @returns:
            suf_ngram: {"suf_-2_the": 1, "suf_-1_cat": 1, ...}
            pos_ngram: {"suf_-2_DT": 1, "suf_-1_NN": 1, ...}
        """
        try:
            if not v_idx:
                v_idx = self.v_idx
            suf_ngram = {}
            pos_ngram = {}
            window = int((n - 1)/2)
            if not v_idx:
                v_idx = 0
            core = self.WL[v_idx]
            _lefts = [word for index, word in enumerate(self.SUF) if index < v_idx and index != v_idx][-window:]
            _leftp = [word for index, word in enumerate(self.POS) if index < v_idx and index != v_idx][-window:]
            _rights = [word for index, word in enumerate(self.SUF) if index > v_idx and index != v_idx][:window]
            _rightp = [word for index, word in enumerate(self.POS) if index > v_idx and index != v_idx][:window]
            concats = _lefts + ["*V*"] + _rights
            concatp = _leftp + ["*V*"] + _rightp
            suf_unigram = {SimpleFeatureExtractor.gen_fn(["SUF1G", str(i-window), "".join(w)]):1 
                        for i, w in enumerate(concats) if w != "*V*"}
            pos_unigram = {SimpleFeatureExtractor.gen_fn(["POS1G", str(i-window), "".join(w)]):1 
                        for i, w in enumerate(concatp) if w != "*V*"}
            suf_bigram = {SimpleFeatureExtractor.gen_fn(["SUF2G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concats, 3)) if w[0] == "*V*" or w[2] == "*V*"} if n >= 5 else {}
            pos_bigram = {SimpleFeatureExtractor.gen_fn(["POS2G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concatp, 3)) if w[0] == "*V*" or w[2] == "*V*"} if n >= 5 else {}
            suf_trigram = {SimpleFeatureExtractor.gen_fn(["SUF3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concats, 4)) if w[0] == "*V*" or w[3] == "*V*"} if n >= 7 else {}
            pos_trigram = {SimpleFeatureExtractor.gen_fn(["POS3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concatp, 4)) if w[0] == "*V*" or w[3] == "*V*"} if n >= 7 else {}
            suf_c3gram = {SimpleFeatureExtractor.gen_fn(["SUF3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concats, 3)) if w[1] == "*V*"} if n >= 3 else {}
            # suf_c5gram = {SimpleFeatureExtractor.gen_fn(["SUF5G", "", "-".join(w)]):1 
            #             for i, w in enumerate(ng(concats, 5)) if w[2] == "*V*"} if n >= 5 else {}
            # suf_c7gram = {SimpleFeatureExtractor.gen_fn(["SUF7G", "", "-".join(w)]):1 
                        # for i, w in enumerate(ng(concats, 7)) if w[3] == "*V*"} if n >= 7 else {}
            pos_c3gram = {SimpleFeatureExtractor.gen_fn(["POS3G", "", "-".join(w)]):1 
                        for i, w in enumerate(ng(concatp, 3)) if w[1] == "*V*"} if n >= 3 else {}
            # pos_c5gram = {SimpleFeatureExtractor.gen_fn(["POS5G", "", "-".join(w)]):1 
            #             for i, w in enumerate(ng(concatp, 5)) if w[2] == "*V*"} if n >= 5 else {}
            # pos_c7gram = {SimpleFeatureExtractor.gen_fn(["POS7G", "", "-".join(w)]):1 
                        # for i, w in enumerate(ng(concatp, 7)) if w[3] == "*V*"} if n >= 7 else {}
            self.features.update(suf_unigram)
            self.features.update(pos_unigram)
            self.features.update(suf_bigram)
            self.features.update(pos_bigram)
            self.features.update(suf_trigram)
            self.features.update(pos_trigram)
            self.features.update(suf_c3gram)
            # self.features.update(suf_c5gram)
            # self.features.update(suf_c7gram)
            self.features.update(pos_c3gram)
            # self.features.update(pos_c5gram)
            # self.features.update(pos_c7gram)
        except Exception, e:
            pass
            # self.features.update(SimpleFeatureExtractor.nullfeature)

    def chunk(self, v_idx=None):
        try:
            if not v_idx:
                v_idx = self.v_idx
            l_ctxid = [idx for idx, pt in enumerate(self.POS) if idx < v_idx and pt.startswith("NN")]
            r_ctxid = [idx for idx, pt in enumerate(self.POS) if idx > v_idx and pt.startswith("NN")]
            lnn = self.SUF[l_ctxid[-1]] if l_ctxid else None
            rnn = self.SUF[r_ctxid[0]] if r_ctxid else None
            l_nearestNN = {"NNL_%s"%lnn: 1} if lnn else {}
            r_nearestNN = {"NNR_%s"%rnn : 1} if rnn else {}
            self.features.update(l_nearestNN)
            self.features.update(r_nearestNN)
            lnnbc = BCluster.getbits(lnn)
            rnnbc = BCluster.getbits(rnn)
            l_nearestNN = {"NNLBC%d_%s"%(d,lnnbc[:d]):1 for d in [8,9]} if lnnbc else {}
            r_nearestNN = {"NNRBC%d_%s"%(d,rnnbc[:d]):1 for d in [8,9]} if rnnbc else {}
            self.features.update(l_nearestNN)
            self.features.update(r_nearestNN)
        except:
            pass



class FeatureExtractor(SimpleFeatureExtractor):
    def dependency(self, v_idx=None):
        try:
            if not v_idx:
                v_idx = self.v_idx
            deps = [(t[FeatureExtractor.col_deprel], t[FeatureExtractor.col_suf], 
                     BCluster.getbits(t[FeatureExtractor.col_suf])) for t in self.tags
                     if int(t[FeatureExtractor.col_headid]) == v_idx+1]
            depp = {FeatureExtractor.gen_fn(["DEP", d[0].upper(), d[1].lower()]):1 for d in deps}
            self.features.update(depp)
            depbc = {FeatureExtractor.gen_fn(["DEPBC", d[0].upper(), d[2]]):1 for d in deps if d[2]}
            self.features.update(depbc)
        except Exception, e:
            logging.debug(pformat(e))
            # self.features.update(FeatureExtractor.nullfeature)


    def ne(self, v_idx=None):
        try:
            if not v_idx:
                v_idx = self.v_idx
            ne = self.tags[v_idx][FeatureExtractor.col_netag]
            ne_tag = {"V-NE_" + ne: 1} if not ne == "_" else {}
            self.features.update(ne_tag)
        except Exception, e:
            logging.debug(pformat(e))

    def bcv(self, v_idx=None):
        try:
            if not v_idx:
                v_idx = self.v_idx
            bcv = BCluster.getbits(self.SUF[v_idx])
            bcf = {"VBC%d_%s"%(d,bcv[:d]):1 for d in [7, 8, 9]} if bcv else {}
            self.features.update(bcf)
        except Exception, e:
            logging.debug(pformat(e))

    @classmethod
    def __format_srl(cls, srldic):
        srl= []
        moc = ("","","","")
        for pkey in srldic:
            out = {}
            out["PRED"] = (pkey[cls.col_suf], pkey[cls.col_pos], pkey[cls.col_deprel], pkey[cls.col_netag])
            try:
                a0 = srldic[pkey]["ARG0"]
                out["ARG0"] = (a0[cls.col_suf], a0[cls.col_pos], a0[cls.col_deprel], a0[cls.col_netag])
            except KeyError:
                out["ARG0"] = moc 
            try:
                a1 = srldic[pkey]["ARG1"]
                out["ARG1"] = (a1[cls.col_suf], a1[cls.col_pos], a1[cls.col_deprel], a1[cls.col_netag])
            except KeyError:
                out["ARG1"] = moc 
            srl.append(out)
        return srl


    def srl(self, v_idx=None):
        try:
            if not v_idx:
                v_idx = self.v_idx
            self.tmp_ARG0 = []
            self.tmp_ARG1 = []
            self.tmp_PRED = defaultdict(dict)
            ARGS = [(l[FeatureExtractor.col_srlrel], l[FeatureExtractor.col_suf], 
                     l[FeatureExtractor.col_pos], l[FeatureExtractor.col_netag]) for l in self.tags 
                    if l[FeatureExtractor.col_srl] != "_" and int(l[FeatureExtractor.col_srl]) - 1 == v_idx]
            if ARGS:
                srlf = {FeatureExtractor.gen_fn(["SRL", t[0], en.lemma(t[1])]):1 for t in ARGS}
                # srlp = {FeatureExtractor.gen_fn(["SRL", t[0], en.lemma(t[1])+"/"+t[2]]):1 for t in ARGS}
                srln = {FeatureExtractor.gen_fn(["SRL", t[0], t[3]]):1 for t in ARGS if not t[3]=="_"}
                self.features.update(srlf)
                # self.features.update(srlp)
                self.features.update(srln)
        except Exception, e:
            logging.debug(pformat(e))
            # self.features.update(FeatureExtractor.nullfeature)

    @classmethod
    def _load_errorprobs(cls, vspath=None):
        if vspath:
            cls.dic_errorprobs = pickle.load(open(vspath, "rb"))
        else:
            raise IOError


    def _read_errorprob(self):
        try:
            prob_v = FeatureExtractor.dic_errorprobs[self.v]
        except KeyError:
            prob_v = FeatureExtractor.dic_errorprobs[en.lemma(self.v)]
        finally:
            pass

    def errorprob(self, vspath=None):
        if FeatureExtractor.dic_errorprobs:
            pass
        else:
            try:
                _load_errorprobs(vspath)
            except IOError:
                pass


    def topic(self):
        raise NotImplementedError
