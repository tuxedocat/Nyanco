#! /usr/bin/env python
# coding: utf-8
'''
Nyanco/src/detector.py
Created on 9 Sep. 2012
'''
__author__ = "Yu Sawai"
__copyright__ = "Copyright 2012, Yu Sawai"
__version__ = "0"
__status__ = "Prototyping"

import os
import nltk
from pprint import pformat
from collections import defaultdict
import cPickle as pickle
from datetime import datetime
logfilename = datetime.now().strftime("detector_log_%Y%m%d_%H%M.log")
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG,
                    filename='../log/'+logfilename)
from nltk import ngrams


class DetectorBase(object):
    def __init__(self, corpusdictpath):
        if os.path.exists(corpusdictpath):
            with open(corpusdictpath, "rb") as f:
                corpusdict = pickle.load(f)
                self.corpus = corpusdict
            self.experimentset = defaultdict(dict)
        else:
            raise IOError

    def make_cases(self):
        """
        Makes test instances entirely on the corpus, just a wrapper
        """
        self.testcases = defaultdict(dict)
        self.case_keys = []
        for docname, doc in self.corpus.iteritems():
            try:
                self._mk_cases(docname, doc)
            except KeyError as ke:
                logging.debug(pformat(ke))
            
            except Exception as e:
                logging.debug("error catched in make_cases")
                logging.debug(pformat(e))

    def detect(self):
        raise NotImplementedError

    def evaluate(self):
        raise NotImplementedError



class LM_Detector(DetectorBase):
    def read_LM_and_PASLM(self, path_IRSTLM="", path_PASLM=""):
        import lsa_test.irstlm
        if path_IRSTLM:
            self.LM = irstlm.initLM(5, path_IRSTLM)
            logging.debug(pformat("IRSTLM's LM is loaded from %s"%path_IRSTLM))
        if path_PASLM:
            self.pasFreqDict = pickle.load(open(path_PASLM))
            logging.debug(pformat("PASLM is loaded"))


    def _mk_ngram_queries(self, n=5, cp_pos=None, w_list=[], alt_candidates=[]):
        """
        Make a query for ngram frequency counter
            nltk.ngrams returns when `pad_right=True, pad_symbol=" "`
                [('I', 'have', 'a', 'black', 'cat.'),
                ('have', 'a', 'black', 'cat.', ' '), 
                ('a', 'black', 'cat.', ' ', ' '), 
                ('black', 'cat.', ' ', ' ', ' '), 
                ('cat.', ' ', ' ', ' ', ' ')]
        First, find index of checkpoint `a` (2), then for n=5, index of the desired tuple is `cp_pos - (n-1)/2`
        @takes:
            n :: N gram size (if n=2, [-2 -1 word +1 +2])
            cp_pos:: int, positional index of the checkpoint
            w_list:: list, words of a sentence
            alt_candidates:: list, alternative candidates if given
        @returns:
            org_q:: string, queries for irstlm.getSentenceScore (Original word)
            alt_q:: list of string, queries for irstlm.getSentenceScore (Generated by given candidates)
            moc_smart_alt_q:: list of string, ad hoc moc of Smartquery
                                    just concatenate heads 
        """
        org_q = []
        alt_q = []
        try:
            ngrams_l = ngrams(w_list, n=n, pad_right=True, pad_symbol=" ")
            query = ngrams_l[cp_pos - (n-1)/2]
            if alt_candidates:
                for cand in alt_candidates:
                    tmp = list(query[:])
                    tmpi = int((n - 1)/2)
                    tmp.pop(tmpi)
                    tmp.insert(tmpi, cand)
                    alt_q.append(u" ".join(tmp))
            else:
                alt_q.append(u" ".join(query))
            org_q = " ".join(query)
        except Exception as nge:
            logging.debug(format(w_list, cp_pos))
            logging.debug(pformat(nge))
        return org_q, alt_q


    def _mk_PAS_queries(self, pasdiclist=[], org_preds=[], alt_preds=[]):
        org_pas_q = []
        alt_pas_q = []
        for pdic in pasdiclist:
            PRED = pdic["PRED"][0]
            ARG0 = pdic["ARG0"][0]
            ARG1 = pdic["ARG1"][0]
            tmp = (PRED, ARG0, ARG1)
            if PRED in org_preds:
                org_pas_q.append(tmp)
            if PRED in alt_preds:
                alt_pas_q.append(tmp)
        org_pas_q = list(set(org_pas_q))
        alt_pas_q = list(set(alt_pas_q))
        if org_pas_q and alt_pas_q:
            logging.debug(pformat(org_pas_q))
            logging.debug(pformat(alt_pas_q))
        return org_pas_q, alt_pas_q


    def _mk_cases(self, docname="", doc=None):
        if docname and doc:
            try:
                gold_tags = doc["gold_tags"]
                test_tags = doc["RVtest_tags"]
                gold_text = doc["gold_text"]
                test_text = doc["RVtest_text"]
                gold_words = doc["gold_words"]
                test_words = doc["RVtest_words"]
                gold_pas = doc["gold_PAS"]
                test_pas = doc["RVtest_PAS"]
                checkpoints = doc["errorposition"]
                for cpid, cp in enumerate(checkpoints):
                    testkey = docname+"_checkpoint"+str(cpid)
                    self.case_keys.append(testkey)
                    cp_pos = cp[0]
                    incorr = cp[1]
                    gold = cp[2]
                    test_wl = test_words[cpid]
                    query_altwords = [gold]
                    self.testcases[testkey]["checkpoint_idx"] = cp_pos
                    self.testcases[testkey]["incorrect_label"] = incorr
                    self.testcases[testkey]["gold_label"] = gold
                    org_q, alt_q = self._mk_ngram_queries(n=5, cp_pos=cp_pos, w_list=test_wl, alt_candidates=query_altwords)
                    self.testcases[testkey]["LM_queries"] = {"org":org_q, "alt":alt_q}
                    self.testcases[testkey]["PASLM_queries"] = self._mk_PAS_queries(pasdiclist=gold_pas+test_pas, org_preds=[incorr], alt_preds=query_altwords)

            except Exception as e:
                logging.debug("error catched in _mk_cases")
                logging.debug(pformat(testkey))
                logging.debug(pformat(e))

    def LM_count(self):
        for testid in self.case_keys:
            case = self.testcases[testid]
            self.testcases[testid]["LM_scores"] = {"org":[], "alt":[]}
            for org_q in case["LM_queries"]["org"]:
                score = irstlm.getSentenceScore(self.LM, org_q)
                self.testcases[testid]["LM_scores"]["org"].append(score)
            for alt_q in case["LM_queries"]["alt"]:
                score = irstlm.getSentenceScore(self.LM, alt_q)
                self.testcases[testid]["LM_scores"]["alt"].append(score)
            



    def detect(self):
        pass
