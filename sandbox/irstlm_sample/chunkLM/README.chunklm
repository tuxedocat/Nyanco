Class and Chunk Language Models

IRSTLM toolkit allows the use of class and chunk LMs, and a special
handling of input tokens which are concatenation of N>=1 fields separated
by the character #, e.g.

word#lemma#part-of-speech#word-class

The processing is guided by the format of the file passed to Moses or
compile-lm: if it contains just the LM, either in textual or binary format,
it is treated as usual; otherwise, it is supposed to have the following
format:

::: start of the file :::
LMMACRO <lmmacroSize> <selectedField> <collapse>
<lmfilename>
<mapfilename>
::: end of the file :::

where:
 LMMACRO is a reserved keyword
 <lmmacroSize> is a positive integer
 <selectedField> is an integer >=-1
 <collapse> is a boolean value (true, false)
 <lmfilename> is a file containing a LM (format compatible with IRSTLM)
 <mapfilename> is either "null" or a file with a (one|many)-to-one map

The various cases are discussed with examples in the following. Note that
texts with different tokens (words, POS, word#POS pairs...) used either as
input or for training LMs are all derived from the same multifield texts in
order to allow direct comparison of results.


### 1. Field selection

The simplest case is that of the LM in <lmfilename> referring just to one
specific field of the input tokens. In this case, it is possible to specify
the field to be selected before querying the LM through the integer
<selectedField> (0 for the first filed, 1 for the second...). With the
value "-1", no selection is applied and the LM is queried with n-grams of
whole strings.

The other parameters are set as:

<lmmacroSize>: set to the size of the LM in <lmfilename>
<collapse>:    false

The third line optionally reserved to {\tt <mapfilename>} does not exist.


--------
Examples

1.a. selection of the second field:
compile-lm --eval test/test.w-micro cfgfile/cfg.2ndfield
%% Nw=126 PP=2.68 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%

1.b. selection of the first field:
compile-lm --eval test/test.w-micro cfgfile/cfg.1stfield
%% Nw=126 PP=9.71 PPwp=0.00 Nbo=76 Noov=0 OOV=0.00%

The result of the latter case is identical to that obtained with the
standard configuration involving just words, as in:

1.c. compile-lm --eval test/test.w lm/train.en.blm 
%% Nw=126 PP=9.71 PPwp=0.00 Nbo=76 Noov=0 OOV=0.00%


### 2. Class LMs

Possibly, a one-to-one or many-to-one map can be passed through the
<mapfilename> parameter which has the simple format:

::: start of the file :::
w1 class(w1)
w2 class(w2)
 ...
wM class(wM)
::: end of the file :::

The map is applied to each component of ngrams before the LM query.

--------
Examples

2.a. map applied to the second field

compile-lm --eval test/test.w-micro cfgfile/cfg.2ndfld-map
%% Nw=126 PP=16.40 PPwp=0.00 Nbo=33 Noov=0 OOV=0.00%

2.b. just to assess the correctness of the (2.a) result:

compile-lm --eval test/test.macro lm/train.macro.blm
%% Nw=126 PP=16.40 PPwp=0.00 Nbo=33 Noov=0 OOV=0.00%


### 3. Chunk LMs

A particular processing is performed whenever fields are supposed to
correspond to microtags, i.e. the per-word projections of chunk labels. By
means of the <collapse> parameter, it is possible to activate a processing
aiming at collapsing the sequence of microtags defining a chunk. The chunk
LM is then queried with ngrams of chunk labels, in an asynchronous manner
with respect to the sequence of words, as in general chunks consist of more
words.

The collapsing operation is automatically activated if the sequence of
microtags is:

 TAG( TAG+ TAG+ ... TAG+ TAG)

Such a sequence is collapsed into a single chunk label (let us say CHNK) as
long as (TAG / TAG(, TAG+ and TAG) are all mapped into the same label
CHNK. The map into different labels or a different use/position of
characters (, + and ) in the lexicon of tags prevent the collapsing
operation even if <collapse> is set to "true". Of course, if <collapse> is
false, no collapse is attempted.

WARNING: In this context, it assumes an important role the parameter
<lmmacroSize>: it defines the size of the n-gram before the collapsing
operation, that is the number of microtags of the actually processed
sequence. <lmmacroSize> should be large enough to ensure that after the
collapsing operation, the resulting n-gram of chunks is at least of the
size of the LM to be queried (the <lmfilename>). As an example, assuming 
<lmmacroSize>=6, <selectedField>=1, <collapse>=true and 3 the size of the
chunk LM, the following input

on#PP average#NP( 30#NP+ -#NP+ 40#NP+ cm#NP)

will yield to query the LM with just the bigram (PP,NP), instead of a more
informative trigram; for this particular case, the value 6 for
<lmmacroSize> is not enough. On the other side, for efficiency reasons,
<lmmacroSize> cannot be set to an unlimited valued. A reasonable value
could derive from the average number of microtags per chunk (2-3), which
means setting <lmmacroSize> to two-three times the size of the LM in
<lmfilename>.


--------
Examples

3.a. second field, micro->macro map, collapse
compile-lm --eval test/test.w-micro cfgfile/cfg.2ndfld-map-cllps
%% Nw=126 PP=1.84 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%

compile-lm --eval test/test.w-micro cfgfile/cfg.2ndfld-map-cllps --debug 1
%% Nw=126 PP=1.83774013 PPwp=0.00000000 Nbo=0 Noov=0 OOV=0.00000000% logPr=-33.29979642

3.b. whole token,  micro->macro map, collapse
compile-lm --eval test/test.micro cfgfile/cfg.token-map-cllps
%% Nw=126 PP=1.84 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%

3.c.  whole token,  micro->macro map, NO collapse
compile-lm --eval test/test.micro cfgfile/cfg.token-map
%% Nw=126 PP=16.40 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%

Note that the configuration (3.c) gives the same result of that in example
(2.b), as they are equivalent.

3.d. As an actual example related to the "warning" note reported above, the
following configuration with usual LM:

compile-lm --eval test/test.chunk lm/train.macro.blm --debug 1
%% Nw=73 PP=2.85754443 PPwp=0.00000000 Nbo=0 Noov=0 OOV=0.00000000% logPr=-33.28748842

not necessarily yields the same log-likelihood (logPr) - nor the same
perplexity - of case (3.a): in fact, concerning PP, the length of the input
sequence is definitely different (126 tokens before collapsing, 73 after
that); but even the logPr is different (-33.29979642 vs. -33.28748842)
because in (3.a) some 6-grams (<lmmacroSize> is set to 6) after collapsing
reduce to n-grams of size less than 3 (the size of lm/train.macro.blm). By
setting <lmmacroSize> to a larger value (e.g. 8), the same logPr will be
computed.
